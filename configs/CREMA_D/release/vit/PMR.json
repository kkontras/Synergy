{
  "training_params": {
    "seed": 109,
    "batch_size": 8,
    "tdqm_disable": false
  },
  "dataset": {
      "norm_wav_path": "./mydatasets/CREMAD/wav_norm_16000_fold{}.pkl",
      "norm_face_path": "./mydatasets/CREMAD/norm_face_path_fold{}.pkl",
      "return_data" : {"video": false, "spectrogram":false, "audio":true, "face": true},
      "sampling_rate": 16000,
    "data_split": {
         "fold": 0
      }
  },
  "model": {
    "model_class": "Base_Model",
    "args": {
      "d_model": 512, "num_classes": 6, "fc_inner": 64, "dropout": 0.1,
      "shared_pred": true,
      "cls_type": "linear",
      "clip_grad": false,
      "bias_infusion": {
        "method": "Prototype",
        "alpha": 2,
        "starting_epoch": 0,
        "ending_epoch": 1500,
        "use": true,
        "plot": false
      },
      "multi_loss": {
        "multi_supervised_w": {
             "combined": 1, "proto_a": 0, "proto_v": 0, "c": 0, "g": 0
          }
      }
    },
    "load_ongoing": false,
    "save_dir": "PMR_{}.pth.tar",
    "encoders": [
      {
        "model": "Audio_Wav2Vec",
        "args": { "d_model": 512, "num_classes": 6, "fc_inner": 64, "dropout": 0.1},
        "pretrainedEncoder": {"use": false, "dir": "unimodal_audio_VAVL_fold0_lr0.00005_wd5e-6.pth.tar"}
      },
      {
        "model": "Video_FacesConformer",
        "args": {"d_model": 512, "num_classes": 6, "fc_inner": 64, "dropout": 0.1},
        "pretrainedEncoder": {"use": false, "dir": "unimodal_faces_VAVLfold0_lr0.00005_wd5e-6_fold0.pth.tar"}}
    ]
  }
}
